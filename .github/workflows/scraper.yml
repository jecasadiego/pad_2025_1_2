name: Run Python Scraper

on:
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests
          pip install beautifulsoup4
          pip install tqdm

      - name: Set random page count
        id: set_pages
        run: echo "pages=$((1 + RANDOM % 50))" >> $GITHUB_OUTPUT

      - name: Run scraper with random input
        run: |
          echo -e "1\n${{ steps.set_pages.outputs.pages }}" | python src/edu_pad/main.py

      - name: Commit generated files if changed
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git fetch origin main
          git checkout main
          git add -f src/edu_pad/db/*.csv src/edu_pad/db/*.sqlite
          if ! git diff --cached --quiet; then
            git commit -m "chore: add scraped ${{ steps.set_pages.outputs.pages }} pages"
            git pull --rebase origin main
            git push origin main

          else
            echo "âœ… No hay cambios para hacer commit."
          fi
      - name: Upload scraped data as artifact (opcional)
        uses: actions/upload-artifact@v4
        with:
          name: scraped-database
          path: src/edu_pad/db/      

