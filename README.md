# ğŸ“š Proyecto de Web Scraping de Libros con Python

Este proyecto permite extraer informaciÃ³n comercial (tÃ­tulo, precio, disponibilidad y calificaciÃ³n) del sitio [Books to Scrape](https://books.toscrape.com) utilizando tres mÃ©todos de scraping: **BeautifulSoup**, **Selenium** y **Scrapy**. Los resultados se guardan en un archivo `.csv` y una base de datos `.sqlite`.

---

## ğŸš€ InstalaciÃ³n y configuraciÃ³n

### 1. Clona el repositorio y accede a su carpeta

```bash
git clone https://github.com/jecasadiego/pad_2025_1_2.git
```

### 2. Crea y activa un entorno virtual dentro de pad_2025_1_2

**Windows:**

```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/macOS:**

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instala el proyecto

```bash
pip install -e .
```

Esto instalarÃ¡ automÃ¡ticamente todas las dependencias necesarias.

---

## ğŸ§ª Uso desde consola (modo CLI)

```bash
edu-pad-run
```

Este comando te preguntarÃ¡:

- QuÃ© mÃ©todo de scraping deseas usar:
  - `1` â†’ BeautifulSoup
  - `2` â†’ Selenium
  - `3` â†’ Scrapy (solo muestra instrucciones)
- CuÃ¡ntas pÃ¡ginas deseas scrapear (1â€“50)

Los datos se guardan automÃ¡ticamente en:

- `src/edu_pad/db/books_data.csv`
- `src/edu_pad/db/books_data.sqlite`

---

## ğŸ•·ï¸ Uso con Scrapy directamente

### 1. Ve a la carpeta del proyecto Scrapy:

```bash
cd edu_scrapy
```

### 2. Ejecuta el spider indicando cuÃ¡ntas pÃ¡ginas scrapear:

```bash
scrapy crawl books -a pages=10
```

> Los archivos tambiÃ©n se guardarÃ¡n en `src/edu_pad/db/`.

---

## ğŸ—‚ Estructura del proyecto

```
src/
â””â”€â”€ edu_pad/
    â”œâ”€â”€ db/
    â”‚   â”œâ”€â”€ db.py               â† Funciones de guardado en CSV y SQLite
    â”œâ”€â”€ functions/
    â”‚   â””â”€â”€ scraper.py          â† LÃ³gica del scraping con BeautifulSoup y Selenium
    â””â”€â”€ static/
        â””â”€â”€ main.py             â† MenÃº principal (CLI)
edu_scrapy/
â””â”€â”€ edu_scrapy/spiders/books.py â† Spider Scrapy
```

---

## ğŸ“¦ Dependencias principales

- `beautifulsoup4`
- `requests`
- `selenium`
- `webdriver-manager`
- `scrapy`
- `tqdm`

Todas se instalan con `pip install -e .` vÃ­a `setup.py`.

---

## âœï¸ Autor

**Juan Esteban Casadiego Benavides**

---

## ğŸ“„ Licencia

Este proyecto es de uso educativo y libre bajo licencia MIT.